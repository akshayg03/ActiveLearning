{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLAss2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshayg03/ActiveLearning/blob/master/MLAss2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ev5cQP91Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import statistics\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score \n",
        "from sklearn import svm\n",
        "from scipy.stats import entropy\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r02A74j0AB5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = datasets.load_digits()\n",
        "rng = np.random.RandomState(1)\n",
        "indices = np.arange(len(digits.data))\n",
        "rng.shuffle(indices)\n",
        "print(\"The total number of training examples in our dataset are: \" + str(len(indices)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heenyVd1GtZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1a - Active Learning setup.\n",
        "X = digits.data[indices[:500]]\n",
        "y = digits.target[indices[:500]]\n",
        " \n",
        "n_labeled_points = 50\n",
        " \n",
        "X_train = np.copy(X[:n_labeled_points])\n",
        "y_train = np.copy(y[:n_labeled_points])\n",
        " \n",
        "X_test = np.copy(X[50:])\n",
        "y_test = np.copy(y[50:])\n",
        "model = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0,  kernel='rbf')\n",
        "model.fit(X_train,y_train)\n",
        " \n",
        "predicted_labels = model.predict(X_test)\n",
        "  \n",
        "true_labels = y_test\n",
        " \n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "print(cm)\n",
        "print(accuracy_score(true_labels, predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwCj-QtBx6BV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1b1a - Uncertainity Sampling(Least Confident)\n",
        "X = digits.data[indices[:1000]]\n",
        "y = digits.target[indices[:1000]]\n",
        "images = digits.images[indices[:1000]]\n",
        "\n",
        "n_total_samples = len(y)\n",
        "n_labeled_points = 100\n",
        "\n",
        "X_train = np.copy(X[:100])\n",
        "y_train = np.copy(y[:100])\n",
        "\n",
        "X_test = np.copy(X[100:])\n",
        "y_test = np.copy(y[100:])\n",
        "model = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "model.fit(X_train,y_train)\n",
        " \n",
        "predicted_labels = model.predict(X)\n",
        "\n",
        "true_labels = y\n",
        "print(accuracy_score(true_labels, predicted_labels))\n",
        "\n",
        "for i in range(4):\n",
        "    \n",
        "    predicted_prob = model.predict_proba(X_test)\n",
        "    uncertainity_labels = 1 - predicted_prob.max(axis=1)\n",
        "    uncertainity_label_indices = np.argsort(uncertainity_labels)\n",
        "    uncertainity_label_indices = uncertainity_label_indices[:100]\n",
        "    #print(uncertainity_label_indices)\n",
        "    #print(len(uncertainity_label_indices))\n",
        "\n",
        "    X_train = np.concatenate((X_train,X_test[uncertainity_label_indices]))\n",
        "    y_train = np.concatenate((y_train,y_test[uncertainity_label_indices]))\n",
        "\n",
        "    X_test = np.delete(X_test,uncertainity_label_indices,0)\n",
        "    y_test = np.delete(y_test,uncertainity_label_indices)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    predicted_labels = model.predict(X)\n",
        "    true_labels = y\n",
        "\n",
        "    #cm = confusion_matrix(true_labels, predicted_labels)\n",
        "    #print(cm)\n",
        "    print(accuracy_score(true_labels, predicted_labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH0tlHfFO-Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1b1b - Uncertainity Sampling(Margin Sampling)\n",
        "X = digits.data[indices[:1000]]\n",
        "y = digits.target[indices[:1000]]\n",
        "images = digits.images[indices[:1000]]\n",
        "\n",
        "n_total_samples = len(y)\n",
        "n_labeled_points = 100\n",
        "\n",
        "X_train = np.copy(X[:100])\n",
        "y_train = np.copy(y[:100])\n",
        "\n",
        "X_test = np.copy(X[100:])\n",
        "y_test = np.copy(y[100:])\n",
        "model = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "model.fit(X_train,y_train)\n",
        " \n",
        "predicted_labels = model.predict(X)\n",
        "\n",
        "true_labels = y\n",
        "print(accuracy_score(true_labels, predicted_labels))\n",
        "\n",
        "for i in range(4):\n",
        "    \n",
        "    predicted_prob = model.predict_proba(X_test)\n",
        "    part = np.partition(-predicted_prob, 1, axis=1)\n",
        "    uncertainity_labels = - part[:, 0] + part[:, 1]\n",
        "    uncertainity_label_indices = np.argsort(uncertainity_labels)\n",
        "    uncertainity_label_indices = uncertainity_label_indices[:100]\n",
        "\n",
        "   \n",
        "    #print(uncertainity_label_indices)\n",
        "    #print(len(uncertainity_label_indices))\n",
        "\n",
        "    X_train = np.concatenate((X_train,X_test[uncertainity_label_indices]))\n",
        "    y_train = np.concatenate((y_train,y_test[uncertainity_label_indices]))\n",
        "\n",
        "    X_test = np.delete(X_test,uncertainity_label_indices,0)\n",
        "    y_test = np.delete(y_test,uncertainity_label_indices)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    predicted_labels = model.predict(X)\n",
        "    true_labels = y\n",
        "\n",
        "    # cm = confusion_matrix(true_labels, predicted_labels)\n",
        "    # print(cm)\n",
        "    print(accuracy_score(true_labels, predicted_labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYzvfhmkRDBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1b1c - Uncertainity Sampling(Entropy)\n",
        "X = digits.data[indices[:1000]]\n",
        "y = digits.target[indices[:1000]]\n",
        "images = digits.images[indices[:1000]]\n",
        "\n",
        "n_total_samples = len(y)\n",
        "n_labeled_points = 100\n",
        "\n",
        "X_train = np.copy(X[:100])\n",
        "y_train = np.copy(y[:100])\n",
        "\n",
        "X_test = np.copy(X[100:])\n",
        "y_test = np.copy(y[100:])\n",
        "model = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "model.fit(X_train,y_train)\n",
        " \n",
        "predicted_labels = model.predict(X)\n",
        "\n",
        "true_labels = y\n",
        "print(accuracy_score(true_labels, predicted_labels))\n",
        "\n",
        "for i in range(4):\n",
        "    \n",
        "    predicted_prob = model.predict_proba(X_test)\n",
        "    uncertainity_labels = entropy(predicted_prob.T)\n",
        "    uncertainity_label_indices = np.argsort(uncertainity_labels)\n",
        "    uncertainity_label_indices = uncertainity_label_indices[:100]\n",
        "\n",
        "   \n",
        "    #print(uncertainity_label_indices)\n",
        "    #print(len(uncertainity_label_indices))\n",
        "\n",
        "    X_train = np.concatenate((X_train,X_test[uncertainity_label_indices]))\n",
        "    y_train = np.concatenate((y_train,y_test[uncertainity_label_indices]))\n",
        "\n",
        "    X_test = np.delete(X_test,uncertainity_label_indices,0)\n",
        "    y_test = np.delete(y_test,uncertainity_label_indices)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    predicted_labels = model.predict(X)\n",
        "    true_labels = y\n",
        "\n",
        "    # cm = confusion_matrix(true_labels, predicted_labels)\n",
        "    # print(cm)\n",
        "    print(accuracy_score(true_labels, predicted_labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ08JMqIXoAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1b2a - Query by committee(Vote Entropy)\n",
        "X = digits.data[indices[:1000]]\n",
        "y = digits.target[indices[:1000]]\n",
        "images = digits.images[indices[:1000]]\n",
        "\n",
        "n_total_samples = len(y)\n",
        "n_labeled_points = 100\n",
        "\n",
        "X_train = np.copy(X[:100])\n",
        "y_train = np.copy(y[:100])\n",
        "\n",
        "X_test = np.copy(X[100:])\n",
        "y_test = np.copy(y[100:])\n",
        "p = np.arange(4500).reshape(900,5)\n",
        "\n",
        "\n",
        "r1 = np.random.RandomState(1)\n",
        "r2 = np.random.RandomState(2)\n",
        "indices1_QBC = np.arange(len(X_train))\n",
        "indices2_QBC = np.arange(len(X_test))\n",
        "\n",
        "X_QBC_train = np.random.rand(5,50,64)\n",
        "y_QBC_train = np.random.rand(5,50)\n",
        "X_QBC_test = np.random.rand(5,450,64)\n",
        "y_QBC_test = np.random.rand(5,450)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "    r1.shuffle(indices1_QBC)\n",
        "    r2.shuffle(indices2_QBC)\n",
        "    X_QBC_train[i] = X_train[indices1_QBC[:50]]\n",
        "    y_QBC_train[i] = y_train[indices1_QBC[:50]]\n",
        "    X_QBC_test[i] = X_test[indices2_QBC[:450]]\n",
        "    y_QBC_test[i] = y_test[indices2_QBC[:450]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for _ in range(5):\n",
        "    c1 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c1.fit(X_QBC_train[0],y_QBC_train[0])\n",
        "    c2 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c2.fit(X_QBC_train[1],y_QBC_train[1])\n",
        "    c3 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c3.fit(X_QBC_train[2],y_QBC_train[2])\n",
        "    c4 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c4.fit(X_QBC_train[3],y_QBC_train[3])\n",
        "    c5 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c5.fit(X_QBC_train[4],y_QBC_train[4])\n",
        "    print(c1.score(X_test,y_test),c2.score(X_test,y_test),c3.score(X_test,y_test),c4.score(X_test,y_test),c5.score(X_test,y_test))\n",
        "    p[:,0] = c1.predict(X_test)\n",
        "    p[:,1] = c2.predict(X_test)\n",
        "    p[:,2] = c3.predict(X_test)\n",
        "    p[:,3] = c4.predict(X_test)\n",
        "    p[:,4] = c5.predict(X_test)\n",
        "    Vote = np.arange(10*900).reshape(900,10)\n",
        "    Vote[:,:] = 0\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "        for j in range(5):\n",
        "            Vote[i,p[i,j]-1]+=1\n",
        "\n",
        "    Prob = np.divide(Vote,5)\n",
        "\n",
        "    uncertainity_labels = entropy(Prob.T)\n",
        "    uncertainity_label_indices = np.argsort(uncertainity_labels)\n",
        "    uncertainity_label_indices = uncertainity_label_indices[:100]\n",
        "\n",
        "    X_train = np.concatenate((X_train,X_test[uncertainity_label_indices]))\n",
        "    y_train = np.concatenate((y_train,y_test[uncertainity_label_indices]))\n",
        "\n",
        "    for i in range(5):\n",
        "        r1 = np.random.RandomState(i)\n",
        "        r2 = np.random.RandomState(i*i)\n",
        "        r1.shuffle(indices1_QBC)\n",
        "        r2.shuffle(indices2_QBC)\n",
        "        #r.shuffle(indices1_QBC)\n",
        "        #r.shuffle(indices2_QBC)\n",
        "        X_QBC_train[i] = X_train[indices1_QBC[:50]]\n",
        "        y_QBC_train[i] = y_train[indices1_QBC[:50]]\n",
        "        X_QBC_test[i] = X_test[indices2_QBC[:450]]\n",
        "        y_QBC_test[i] = y_test[indices2_QBC[:450]]\n",
        "\n",
        "    model = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    model.fit(X_train,y_train)\n",
        "    \n",
        "    predicted_labels = model.predict(X)\n",
        "\n",
        "    true_labels = y\n",
        "    print(accuracy_score(true_labels, predicted_labels))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOwqEfXWsRz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1b2b - Query by committee(KL Divergence)\n",
        "X = digits.data[indices[:1000]]\n",
        "y = digits.target[indices[:1000]]\n",
        "images = digits.images[indices[:1000]]\n",
        "\n",
        "n_total_samples = len(y)\n",
        "n_labeled_points = 100\n",
        "\n",
        "X_train = np.copy(X[:100])\n",
        "y_train = np.copy(y[:100])\n",
        "\n",
        "X_test = np.copy(X[100:])\n",
        "y_test = np.copy(y[100:])\n",
        "p = np.arange(4500).reshape(900,5)\n",
        "\n",
        "\n",
        "r1 = np.random.RandomState(1)\n",
        "r2 = np.random.RandomState(2)\n",
        "indices1_QBC = np.arange(len(X_train))\n",
        "indices2_QBC = np.arange(len(X_test))\n",
        "\n",
        "X_QBC_train = np.random.rand(5,50,64)\n",
        "y_QBC_train = np.random.rand(5,50)\n",
        "X_QBC_test = np.random.rand(5,450,64)\n",
        "y_QBC_test = np.random.rand(5,450)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "    r1.shuffle(indices1_QBC)\n",
        "    r2.shuffle(indices2_QBC)\n",
        "    X_QBC_train[i] = X_train[indices1_QBC[:50]]\n",
        "    y_QBC_train[i] = y_train[indices1_QBC[:50]]\n",
        "    X_QBC_test[i] = X_test[indices2_QBC[:450]]\n",
        "    y_QBC_test[i] = y_test[indices2_QBC[:450]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for _ in range(5):\n",
        "    c1 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c1.fit(X_QBC_train[0],y_QBC_train[0])\n",
        "    c2 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c2.fit(X_QBC_train[1],y_QBC_train[1])\n",
        "    c3 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c3.fit(X_QBC_train[2],y_QBC_train[2])\n",
        "    c4 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c4.fit(X_QBC_train[3],y_QBC_train[3])\n",
        "    c5 = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    c5.fit(X_QBC_train[4],y_QBC_train[4])\n",
        "    print(c1.score(X_test,y_test),c2.score(X_test,y_test),c3.score(X_test,y_test),c4.score(X_test,y_test),c5.score(X_test,y_test))\n",
        "    \n",
        "    p[:,0] = c1.predict(X_test)\n",
        "    p[:,1] = c2.predict(X_test)\n",
        "    p[:,2] = c3.predict(X_test)\n",
        "    p[:,3] = c4.predict(X_test)\n",
        "    p[:,4] = c5.predict(X_test)\n",
        "    Vote = np.arange(10*900).reshape(900,10)\n",
        "    Vote[:,:] = 0\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "        for j in range(5):\n",
        "            Vote[i,p[i,j]-1]+=1\n",
        "\n",
        "    Prob = np.divide(Vote,5)\n",
        "    p_consensus = np.random.rand(len(Prob),10)\n",
        "    p_consensus[:,:] = 0.1\n",
        "    uncertainity_labels = entropy(Prob.T,qk=p_consensus.T)\n",
        "    uncertainity_label_indices = np.argsort(uncertainity_labels)\n",
        "    uncertainity_label_indices = uncertainity_label_indices[:100]\n",
        "\n",
        "    X_train = np.concatenate((X_train,X_test[uncertainity_label_indices]))\n",
        "    y_train = np.concatenate((y_train,y_test[uncertainity_label_indices]))\n",
        "\n",
        "    for i in range(5):\n",
        "        r1 = np.random.RandomState(i)\n",
        "        r2 = np.random.RandomState(i*i)\n",
        "        r1.shuffle(indices1_QBC)\n",
        "        r2.shuffle(indices2_QBC)\n",
        "        X_QBC_train[i] = X_train[indices1_QBC[:50]]\n",
        "        y_QBC_train[i] = y_train[indices1_QBC[:50]]\n",
        "        X_QBC_test[i] = X_test[indices2_QBC[:450]]\n",
        "        y_QBC_test[i] = y_test[indices2_QBC[:450]]\n",
        "\n",
        "    model = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "    model.fit(X_train,y_train)\n",
        "    \n",
        "    predicted_labels = model.predict(X)\n",
        "\n",
        "    true_labels = y\n",
        "    print(accuracy_score(true_labels, predicted_labels))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti0iMDWYbYv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1b3 - Version Space and its points indices.\n",
        "version_indices =[]\n",
        "for i in range(len(Vote)):\n",
        "    if(Vote[i,np.argmax(Vote[i])]!=5):\n",
        "        version_indices.append(i)\n",
        "print(\"The size/number of points in of verson space is: \" + str(len(version_indices)))\n",
        "version_vote = Vote[version_indices]\n",
        "\n",
        "version_unique_count = []\n",
        "for i in range(len(version_vote)):\n",
        "    version_unique_count.append(len(np.unique(version_vote[i])))\n",
        "version_unique_count = np.multiply(version_unique_count,-1)\n",
        "version_sort_indices = np.argsort(version_unique_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g29vqoE13R3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1b4 - Random points approach.\n",
        "X = digits.data[indices[:1000]]\n",
        "y = digits.target[indices[:1000]]\n",
        "images = digits.images[indices[:1000]]\n",
        "\n",
        "n_total_samples = len(y)\n",
        "n_labeled_points = 100\n",
        "\n",
        "model = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "\n",
        "for i in range(5):\n",
        "    X_train = X[:50*(i+1)]\n",
        "    y_train = y[:50*(i+1)]\n",
        "\n",
        "    X_test = X[50*(i+1):]\n",
        "    y_test = y[50*(i+1):]\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    predicted_labels = model.predict(X)\n",
        "    true_labels = y\n",
        "\n",
        "    print(accuracy_score(true_labels, predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JATTAD_qJjEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1b4b - Stream based approach.\n",
        "X = digits.data[indices[:500]]\n",
        "y = digits.target[indices[:500]]\n",
        "images = digits.images[indices[:500]]\n",
        "\n",
        "n_total_samples = len(y)\n",
        "n_labeled_points = 50\n",
        "\n",
        "X_train = np.copy(X[:50])\n",
        "y_train = np.copy(y[:50])\n",
        "\n",
        "X_test = np.copy(X[50:])\n",
        "y_test = np.copy(y[50:])\n",
        "model = svm.SVC(decision_function_shape='ovo',probability=True,C=1.0, kernel='rbf')\n",
        "model.fit(X_train,y_train)\n",
        " \n",
        "predicted_labels = model.predict(X)\n",
        "\n",
        "true_labels = y\n",
        "print(accuracy_score(true_labels, predicted_labels))\n",
        "\n",
        " \n",
        "predicted_prob = model.predict_proba(X_test)\n",
        "\n",
        "a = []\n",
        "for i in range(len(predicted_prob)):\n",
        "    a.append(predicted_prob[i][np.argmax(predicted_prob[i])])\n",
        "a = np.array(a) \n",
        "ind = np.argsort(a,axis=0)\n",
        "\n",
        "for i in range(4):\n",
        "  X_train = np.concatenate((X_train,X_test[ind[400-i*50:]]))\n",
        "  y_train = np.concatenate((y_train,y_test[ind[400-i*50:]]))\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        " \n",
        "  predicted_labels = model.predict(X)\n",
        "  true_labels = y\n",
        "  print(accuracy_score(true_labels, predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oWtj71NK4B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1b5 - K-means.\n",
        "X = digits.data[indices[:500]]\n",
        "y = digits.target[indices[:500]]\n",
        "images = digits.images[indices[:500]]\n",
        "\n",
        "x_labeled_10 = np.copy(X[:50])\n",
        "y_labeled_10 = np.copy(y[:50])\n",
        "\n",
        "x_unlabeled_90 = np.copy(X[50:])\n",
        "y_unlabeled_90 = np.copy(y[50:])\n",
        "\n",
        "x_random_40 = np.copy(x_unlabeled_90[:200])\n",
        "y_random_40 = np.copy(y_unlabeled_90[:200])\n",
        "\n",
        "k_means = x_random_40[:10]\n",
        "k_means_cur = x_random_40[20:30]\n",
        "\n",
        "money = 0\n",
        "time = 0\n",
        "clusters = np.zeros(200,dtype = int)\n",
        "y_final = np.zeros(200,dtype = int)\n",
        "distances = np.zeros(10)\n",
        "flag = False\n",
        "\n",
        "for i in range(10000):\n",
        "  # print(k_means)\n",
        "  for j in range(200):\n",
        "    for k in range(10):\n",
        "      distances[k] = np.linalg.norm(x_random_40[j] - k_means[k])\n",
        "    c = np.argmin(distances)\n",
        "    clusters[j] = c\n",
        "\n",
        "  for j in range(10):\n",
        "    c = np.where(clusters == j)\n",
        "    s = np.average(x_random_40[c], axis = 0)\n",
        "    k_means_cur[j] = s\n",
        "\n",
        "  flag = np.array_equal(k_means_cur,k_means)\n",
        "  if(flag):\n",
        "    break\n",
        "  k_means = np.copy(k_means_cur)\n",
        "\n",
        "for j in range(10):\n",
        "    c = np.where(clusters == j)\n",
        "    len_1 = int(0.2*len(c[0])+1)\n",
        "    labeled = y_random_40[c[0][:len_1]]\n",
        "    money += len(labeled) * 100\n",
        "    time += len(labeled)\n",
        "\n",
        "    try:\n",
        "      most_freq = statistics.mode(labeled)\n",
        "    except statistics.StatisticsError:\n",
        "      most_freq = labeled[0]\n",
        "    \n",
        "    y_final[c] = most_freq\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_final, y_random_40)\n",
        "print(cm)\n",
        "print(\"the accuracy is : \",accuracy_score(y_final, y_random_40))\n",
        "print(\"it would take \", money, \"rupees \\nand it would take \", time, \"hours to label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h42KBql9QIjU",
        "colab_type": "text"
      },
      "source": [
        "Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdtcsZZWQK58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2 - Self Organizing Maps(SOMs)\n",
        "!pip install SimpSOM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N1cTk7LQdgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import SimpSOM as sps\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjDQtd4UQpV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = load_wine()\n",
        "x = dataset.data\n",
        "y = dataset.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN2JsC1kQjbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = sps.somNet(10, 10, x, PBC=True)\n",
        "net.train(0.01, 20000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDT_9NGIRo05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.diff_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifo2jMF1QneL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.nodes_graph(colnum=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNoKPfn3RkTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.nodes_graph(colnum=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GptXTVhRmfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.nodes_graph(colnum=9)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}